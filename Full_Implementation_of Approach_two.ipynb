{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stephen's Code for Appproach 2 Events Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labraries Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/steve/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer               #WordNetLemmatizer\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataSet Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = []\n",
    "train_categories = []\n",
    "\n",
    "with open(\"final_data.csv\", \"r\") as file:\n",
    "    csv_reader = csv.reader(file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for rows in csv_reader:\n",
    "        if line_count == 0:\n",
    "            pass\n",
    "        else:\n",
    "            train_text.append(rows[1])\n",
    "            train_categories.append(rows[3])\n",
    "        line_count += 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preproccessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_categories = [x.lower() for x in train_categories]\n",
    "\n",
    "def normalize(train_text):\n",
    "    \n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    new_traintext = []\n",
    "    \n",
    "    for t_text in train_text:\n",
    "        \n",
    "        text = t_text\n",
    "        \n",
    "        #Remove reply identifiers. Ex: \"Reply to @Someone: ....\"\n",
    "        text = re.sub(r\"Reply to @\\w.*:\", \"\", text)\n",
    "        \n",
    "        #Remove IDs. Ex: \"@someone\"\n",
    "        text = re.sub(r\"@\\w+\\s*\", \"\", text)\n",
    "        \n",
    "        #Remove all special characters \n",
    "        text = re.sub(r'\\W', ' ', text)\n",
    "        \n",
    "        #Remove all single characters\n",
    "        text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)\n",
    "        \n",
    "        # Remove single characters from the start\n",
    "        text = re.sub(r'\\^[a-zA-Z]\\s+', ' ', text) \n",
    "    \n",
    "        #Substituting multiple spaces with single space\n",
    "        text = re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "        \n",
    "        text = re.sub(r'^b\\s+', '', text)\n",
    "        \n",
    "        text = text.lower()\n",
    "        \n",
    "        text = text.split()\n",
    "\n",
    "        text = [stemmer.stem(word) for word in text]\n",
    "        text = ' '.join(text)\n",
    "    \n",
    "        new_traintext.append(text)\n",
    "        \n",
    "    return new_traintext\n",
    "\n",
    "\n",
    "\n",
    "train_text = normalize(train_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Text Numerical value conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "tfidfconverter = TfidfVectorizer(\n",
    "    max_features = 1500,\n",
    "    min_df = 5,\n",
    "    max_df = 0.7,\n",
    "    \n",
    "    stop_words = stopwords.words('english')\n",
    ")\n",
    "\n",
    "X = tfidfconverter.fit_transform(train_text).toarray()\n",
    "\n",
    "\n",
    "# Save the vocabulary to calculate TF/IDFs on the fly from new tweets\n",
    "vocab = tfidfconverter.vocabulary_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splitting: Train Set And Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, train_categories ,test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier0 = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "classifier0.fit(X_train, y_train) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier1 = KNeighborsClassifier(n_neighbors=5)\n",
    "classifier1.fit(X_train, y_train) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier2 =  LinearSVC()\n",
    "classifier2.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier3 = BernoulliNB()\n",
    "classifier3.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestCentroid(metric='euclidean', shrink_threshold=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier4 = NearestCentroid()\n",
    "classifier4.fit(X_train, y_train) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9128386336866903\n",
      "[[  0   0   0 ...   0   0   0]\n",
      " [  0   0   2 ...   0   0   0]\n",
      " [  0   0 330 ...   0   1   0]\n",
      " ...\n",
      " [  0   0   0 ...  21   0   0]\n",
      " [  0   0   1 ...   1 112   0]\n",
      " [  0   0   0 ...   0   0   2]]\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "                        accidents       0.00      0.00      0.00         1\n",
      "          acts of violence or war       0.00      0.00      0.00         5\n",
      "      armed conflicts and attacks       0.92      0.96      0.94       345\n",
      "                 arts and culture       0.83      0.78      0.80        67\n",
      "           business and economics       0.97      0.81      0.88        42\n",
      "             business and economy       0.88      0.90      0.89        51\n",
      "celebrity and human interest news       0.35      0.45      0.39        20\n",
      "                        disasters       0.90      0.89      0.90        72\n",
      "          disasters and accidents       0.88      0.88      0.88        33\n",
      "                        elections       0.87      0.86      0.86        92\n",
      "                      exploration       1.00      1.00      1.00        11\n",
      "                   financial news       1.00      1.00      1.00         2\n",
      "                           health       0.80      1.00      0.89         8\n",
      "                          history       1.00      1.00      1.00         4\n",
      "                     human rights       1.00      0.17      0.29         6\n",
      "        innovation and technology       1.00      0.87      0.93        15\n",
      "          international relations       0.89      0.80      0.84        71\n",
      "                    law and crime       0.89      0.92      0.91       271\n",
      "             legal/criminal cases       0.00      0.00      0.00         4\n",
      "                       literature       1.00      0.78      0.88         9\n",
      "               miscellaneous news       0.40      0.14      0.21        29\n",
      "                 natural disaster       0.60      0.25      0.35        12\n",
      "                         new laws       0.00      0.00      0.00         2\n",
      "                        non_event       0.95      0.98      0.96      1722\n",
      "political and diplomatic meetings       0.33      0.25      0.29         8\n",
      "                         politics       0.96      0.82      0.88        28\n",
      "           politics and elections       0.82      0.89      0.85       148\n",
      "                         religion       1.00      0.86      0.92         7\n",
      "           religion and diplomacy       1.00      1.00      1.00        14\n",
      "        religion and spirituality       1.00      1.00      1.00         1\n",
      "                scandals/hearings       0.00      0.00      0.00         4\n",
      "                          science       0.89      1.00      0.94         8\n",
      "       science and discovery news       0.50      0.33      0.40         9\n",
      "           science and technology       1.00      0.86      0.92         7\n",
      "                            sport       0.89      0.87      0.88        98\n",
      "                           sports       0.88      0.95      0.91        22\n",
      "                      sports news       0.85      0.77      0.81       146\n",
      "                        transport       1.00      1.00      1.00         2\n",
      "\n",
      "                        micro avg       0.91      0.91      0.91      3396\n",
      "                        macro avg       0.74      0.68      0.70      3396\n",
      "                     weighted avg       0.91      0.91      0.91      3396\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/steve/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_predict = classifier0.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test,y_predict))\n",
    "print(confusion_matrix(y_test,y_predict))\n",
    "print(classification_report(y_test,y_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8130153121319199\n",
      "[[  0   0   0 ...   0   0   0]\n",
      " [  0   0   3 ...   0   1   0]\n",
      " [  0   0 333 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...  21   0   0]\n",
      " [  0   0   4 ...   2  95   0]\n",
      " [  0   0   0 ...   0   0   2]]\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "                        accidents       0.00      0.00      0.00         1\n",
      "          acts of violence or war       0.00      0.00      0.00         5\n",
      "      armed conflicts and attacks       0.84      0.97      0.90       345\n",
      "                 arts and culture       0.27      0.82      0.41        67\n",
      "           business and economics       0.92      0.79      0.85        42\n",
      "             business and economy       0.90      0.84      0.87        51\n",
      "celebrity and human interest news       0.37      0.50      0.43        20\n",
      "                        disasters       0.92      0.90      0.91        72\n",
      "          disasters and accidents       0.91      0.88      0.89        33\n",
      "                        elections       0.86      0.80      0.83        92\n",
      "                      exploration       1.00      1.00      1.00        11\n",
      "                   financial news       1.00      1.00      1.00         2\n",
      "                           health       0.71      0.62      0.67         8\n",
      "                          history       1.00      1.00      1.00         4\n",
      "                     human rights       1.00      0.33      0.50         6\n",
      "        innovation and technology       0.87      0.87      0.87        15\n",
      "          international relations       0.65      0.80      0.72        71\n",
      "                    law and crime       0.79      0.92      0.85       271\n",
      "             legal/criminal cases       0.00      0.00      0.00         4\n",
      "                       literature       1.00      0.89      0.94         9\n",
      "               miscellaneous news       0.33      0.24      0.28        29\n",
      "                 natural disaster       0.86      0.50      0.63        12\n",
      "                         new laws       0.00      0.00      0.00         2\n",
      "                        non_event       0.93      0.79      0.86      1722\n",
      "political and diplomatic meetings       0.00      0.00      0.00         8\n",
      "                         politics       0.86      0.68      0.76        28\n",
      "           politics and elections       0.87      0.89      0.88       148\n",
      "                         religion       1.00      0.71      0.83         7\n",
      "           religion and diplomacy       1.00      1.00      1.00        14\n",
      "        religion and spirituality       1.00      1.00      1.00         1\n",
      "                scandals/hearings       0.00      0.00      0.00         4\n",
      "                          science       0.80      1.00      0.89         8\n",
      "       science and discovery news       0.50      0.22      0.31         9\n",
      "           science and technology       1.00      0.86      0.92         7\n",
      "                            sport       0.88      0.87      0.87        98\n",
      "                           sports       0.84      0.95      0.89        22\n",
      "                      sports news       0.45      0.65      0.54       146\n",
      "                        transport       0.67      1.00      0.80         2\n",
      "\n",
      "                        micro avg       0.81      0.81      0.81      3396\n",
      "                        macro avg       0.68      0.67      0.66      3396\n",
      "                     weighted avg       0.85      0.81      0.82      3396\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/steve/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_predict = classifier1.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test,y_predict))\n",
    "print(confusion_matrix(y_test,y_predict))\n",
    "print(classification_report(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9178445229681979\n",
      "[[  0   0   0 ...   0   0   0]\n",
      " [  0   0   3 ...   0   0   0]\n",
      " [  0   0 329 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...  21   0   0]\n",
      " [  0   0   0 ...   1 108   0]\n",
      " [  0   0   0 ...   0   0   2]]\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "                        accidents       0.00      0.00      0.00         1\n",
      "          acts of violence or war       0.00      0.00      0.00         5\n",
      "      armed conflicts and attacks       0.96      0.95      0.96       345\n",
      "                 arts and culture       0.84      0.79      0.82        67\n",
      "           business and economics       0.95      0.83      0.89        42\n",
      "             business and economy       0.94      0.88      0.91        51\n",
      "celebrity and human interest news       0.60      0.45      0.51        20\n",
      "                        disasters       0.89      0.92      0.90        72\n",
      "          disasters and accidents       0.90      0.85      0.88        33\n",
      "                        elections       0.84      0.90      0.87        92\n",
      "                      exploration       0.92      1.00      0.96        11\n",
      "                   financial news       1.00      0.50      0.67         2\n",
      "                           health       1.00      0.75      0.86         8\n",
      "                          history       1.00      1.00      1.00         4\n",
      "                     human rights       1.00      0.17      0.29         6\n",
      "        innovation and technology       1.00      0.80      0.89        15\n",
      "          international relations       0.79      0.89      0.83        71\n",
      "                    law and crime       0.88      0.92      0.90       271\n",
      "             legal/criminal cases       0.00      0.00      0.00         4\n",
      "                       literature       1.00      0.89      0.94         9\n",
      "               miscellaneous news       0.33      0.21      0.26        29\n",
      "                 natural disaster       0.88      0.58      0.70        12\n",
      "                         new laws       0.00      0.00      0.00         2\n",
      "                        non_event       0.96      0.98      0.97      1722\n",
      "political and diplomatic meetings       0.00      0.00      0.00         8\n",
      "                         politics       0.92      0.82      0.87        28\n",
      "           politics and elections       0.86      0.92      0.89       148\n",
      "                         religion       1.00      0.71      0.83         7\n",
      "           religion and diplomacy       1.00      1.00      1.00        14\n",
      "        religion and spirituality       1.00      1.00      1.00         1\n",
      "                scandals/hearings       0.00      0.00      0.00         4\n",
      "                          science       0.89      1.00      0.94         8\n",
      "       science and discovery news       0.43      0.33      0.38         9\n",
      "           science and technology       1.00      0.86      0.92         7\n",
      "                            sport       0.84      0.91      0.87        98\n",
      "                           sports       0.91      0.95      0.93        22\n",
      "                      sports news       0.83      0.74      0.78       146\n",
      "                        transport       1.00      1.00      1.00         2\n",
      "\n",
      "                        micro avg       0.92      0.92      0.92      3396\n",
      "                        macro avg       0.75      0.67      0.69      3396\n",
      "                     weighted avg       0.91      0.92      0.91      3396\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/steve/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_predict = classifier2.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test,y_predict))\n",
    "print(confusion_matrix(y_test,y_predict))\n",
    "print(classification_report(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8630742049469965\n",
      "[[  0   0   0 ...   0   0   0]\n",
      " [  0   0   4 ...   0   0   0]\n",
      " [  0   0 337 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   1 ...   0   4   0]\n",
      " [  0   0   3 ...   0 117   0]\n",
      " [  0   0   0 ...   0   1   0]]\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "                        accidents       0.00      0.00      0.00         1\n",
      "          acts of violence or war       0.00      0.00      0.00         5\n",
      "      armed conflicts and attacks       0.82      0.98      0.89       345\n",
      "                 arts and culture       0.64      0.61      0.63        67\n",
      "           business and economics       0.96      0.62      0.75        42\n",
      "             business and economy       0.95      0.76      0.85        51\n",
      "celebrity and human interest news       0.00      0.00      0.00        20\n",
      "                        disasters       0.78      0.86      0.82        72\n",
      "          disasters and accidents       0.84      0.64      0.72        33\n",
      "                        elections       0.85      0.86      0.85        92\n",
      "                      exploration       0.00      0.00      0.00        11\n",
      "                   financial news       0.00      0.00      0.00         2\n",
      "                           health       0.00      0.00      0.00         8\n",
      "                          history       0.00      0.00      0.00         4\n",
      "                     human rights       0.00      0.00      0.00         6\n",
      "        innovation and technology       1.00      0.20      0.33        15\n",
      "          international relations       0.67      0.59      0.63        71\n",
      "                    law and crime       0.76      0.94      0.84       271\n",
      "             legal/criminal cases       0.00      0.00      0.00         4\n",
      "                       literature       0.00      0.00      0.00         9\n",
      "               miscellaneous news       0.30      0.10      0.15        29\n",
      "                 natural disaster       0.00      0.00      0.00        12\n",
      "                         new laws       0.00      0.00      0.00         2\n",
      "                        non_event       0.95      0.97      0.96      1722\n",
      "political and diplomatic meetings       0.00      0.00      0.00         8\n",
      "                         politics       0.89      0.29      0.43        28\n",
      "           politics and elections       0.76      0.88      0.81       148\n",
      "                         religion       0.00      0.00      0.00         7\n",
      "           religion and diplomacy       1.00      0.57      0.73        14\n",
      "        religion and spirituality       0.00      0.00      0.00         1\n",
      "                scandals/hearings       0.00      0.00      0.00         4\n",
      "                          science       1.00      0.38      0.55         8\n",
      "       science and discovery news       0.00      0.00      0.00         9\n",
      "           science and technology       0.00      0.00      0.00         7\n",
      "                            sport       0.82      0.87      0.84        98\n",
      "                           sports       0.00      0.00      0.00        22\n",
      "                      sports news       0.64      0.80      0.71       146\n",
      "                        transport       0.00      0.00      0.00         2\n",
      "\n",
      "                        micro avg       0.86      0.86      0.86      3396\n",
      "                        macro avg       0.39      0.31      0.33      3396\n",
      "                     weighted avg       0.83      0.86      0.84      3396\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/steve/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_predict = classifier3.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test,y_predict))\n",
    "print(confusion_matrix(y_test,y_predict))\n",
    "print(classification_report(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.766489988221437\n",
      "[[  1   0   0 ...   0   0   0]\n",
      " [  0   2   2 ...   0   0   0]\n",
      " [  0   1 274 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...  20   0   0]\n",
      " [  0   2   3 ...   3  96   0]\n",
      " [  0   0   0 ...   0   0   2]]\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "                        accidents       0.09      1.00      0.17         1\n",
      "          acts of violence or war       0.13      0.40      0.20         5\n",
      "      armed conflicts and attacks       0.82      0.79      0.81       345\n",
      "                 arts and culture       0.69      0.54      0.61        67\n",
      "           business and economics       0.86      0.76      0.81        42\n",
      "             business and economy       0.84      0.73      0.78        51\n",
      "celebrity and human interest news       0.25      0.50      0.33        20\n",
      "                        disasters       0.97      0.47      0.64        72\n",
      "          disasters and accidents       0.77      0.82      0.79        33\n",
      "                        elections       0.89      0.52      0.66        92\n",
      "                      exploration       1.00      1.00      1.00        11\n",
      "                   financial news       0.17      1.00      0.29         2\n",
      "                           health       0.71      0.62      0.67         8\n",
      "                          history       1.00      1.00      1.00         4\n",
      "                     human rights       0.09      0.50      0.15         6\n",
      "        innovation and technology       0.87      0.87      0.87        15\n",
      "          international relations       0.51      0.73      0.60        71\n",
      "                    law and crime       0.41      0.74      0.53       271\n",
      "             legal/criminal cases       0.00      0.00      0.00         4\n",
      "                       literature       1.00      0.89      0.94         9\n",
      "               miscellaneous news       0.12      0.17      0.14        29\n",
      "                 natural disaster       0.18      0.58      0.28        12\n",
      "                         new laws       0.00      0.00      0.00         2\n",
      "                        non_event       0.99      0.83      0.90      1722\n",
      "political and diplomatic meetings       0.13      0.38      0.19         8\n",
      "                         politics       0.51      0.75      0.61        28\n",
      "           politics and elections       0.67      0.79      0.72       148\n",
      "                         religion       0.62      0.71      0.67         7\n",
      "           religion and diplomacy       1.00      1.00      1.00        14\n",
      "        religion and spirituality       0.50      1.00      0.67         1\n",
      "                scandals/hearings       0.00      0.00      0.00         4\n",
      "                          science       0.42      0.62      0.50         8\n",
      "       science and discovery news       0.25      0.11      0.15         9\n",
      "           science and technology       0.50      0.71      0.59         7\n",
      "                            sport       0.87      0.79      0.82        98\n",
      "                           sports       0.74      0.91      0.82        22\n",
      "                      sports news       0.84      0.66      0.74       146\n",
      "                        transport       0.50      1.00      0.67         2\n",
      "\n",
      "                        micro avg       0.77      0.77      0.77      3396\n",
      "                        macro avg       0.55      0.66      0.56      3396\n",
      "                     weighted avg       0.84      0.77      0.79      3396\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/steve/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_predict = classifier4.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test,y_predict))\n",
    "print(confusion_matrix(y_test,y_predict))\n",
    "print(classification_report(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Testing of new Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there will be a HUGE football game tonight! => sports news\n",
      "wow .. awesome stuff we saw tonight! => non_event\n",
      "A new actress will feature in a new musical => business and economy\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "tweet1 = \"there will be a HUGE football game tonight!\"\n",
    "tweet2 = \"wow .. awesome stuff we saw tonight!\"\n",
    "tweet3 = \"A new actress will feature in a new musical\"\n",
    "\n",
    "input_list = [tweet1, tweet2, tweet3]\n",
    "\n",
    "# Normalize\n",
    "normalized_input = normalize(input_list)\n",
    "\n",
    "# Extract features\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=1500,\n",
    "    min_df=5,\n",
    "    max_df=0.7,\n",
    "    stop_words=stopwords.words('english'),\n",
    "    vocabulary=vocab # use the vocabulary from the training set\n",
    ")\n",
    "\n",
    "features = vectorizer.fit_transform(normalized_input)\n",
    "\n",
    "# Prediction\n",
    "predictions = classifier0.predict(features)\n",
    "\n",
    "# Output\n",
    "for i in range(len(input_list)):\n",
    "    print(input_list[i], \"=>\", predictions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Interact with Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a Text of Your Choice: Dr. Jelena Mitrovic, please can you evaluate my code today\n",
      "Category:  non_event\n",
      "Enter a Text of Your Choice: There is a University meeting today\n",
      "Category:  non_event\n"
     ]
    }
   ],
   "source": [
    "# Extract features\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=1500,\n",
    "    min_df=5,\n",
    "    max_df=0.7,\n",
    "    stop_words=stopwords.words('english'),\n",
    "    vocabulary=vocab # use the vocabulary from the training set\n",
    ")\n",
    "\n",
    "while(True):\n",
    "    text = input(\"Enter a Text of Your Choice: \")\n",
    "    normalized = normalize([text])\n",
    "    features = vectorizer.fit_transform(normalized)\n",
    "\n",
    "# Prediction\n",
    "    prediction = classifier0.predict(features)\n",
    "    #prediction = classifier1.predict(features)\n",
    "    #prediction = classifier2.predict(features)\n",
    "    #prediction = classifier3.predict(features)\n",
    "    #prediction = classifier4.predict(features)\n",
    "\n",
    "    print(\"Category: \" , prediction[0])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
